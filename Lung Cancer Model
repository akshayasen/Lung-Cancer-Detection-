import os

# Specify the path to your folder
folder_path = r"C:\Users\akshaya\Documents\lung_colon_image_set"

# Check if the specified path is a directory
if os.path.isdir(folder_path):
    print(f"Processing folder: {folder_path}")

    # Walk through the folder and list all files and subfolders
    for root, dirs, files in os.walk(folder_path):
        print(f"Directory: {root}")
        for file in files:
            file_path = os.path.join(root, file)
            print(f"  File: {file_path}")
else:
    print(f"The specified path is not a folder: {folder_path}")
# Setup and Imports
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Set dataset path
DATASET_PATH = r"C:\Users\akshaya\Documents\lung_colon_image_set"

# Define classes (update if needed)
CLASSES = ['lung_n', 'lung_aca', 'lung_scc']

# Verify dataset path
if os.path.isdir(DATASET_PATH):
    print(f"Dataset path is valid: {DATASET_PATH}")
else:
    raise FileNotFoundError(f"Dataset path is not valid: {DATASET_PATH}")
#  Load and Preprocess the Dataset
import os
import numpy as np
import tensorflow as tf

# Path to the dataset
DATASET_PATH = r'C:\Users\akshaya\Documents\lung_colon_image_set\lung_image_sets'

# Dynamically detect classes
CLASSES = os.listdir(DATASET_PATH)
print(f"Detected classes: {CLASSES}")

# Function to load and preprocess data
def load_data(folder_path):
    data = []
    labels = []

    for label in CLASSES:
        class_dir = os.path.join(folder_path, label)
        if not os.path.isdir(class_dir):
            print(f"Warning: Directory not found: {class_dir}")
            continue

        for img in os.listdir(class_dir):
            img_path = os.path.join(class_dir, img)
            try:
                img_array = tf.keras.utils.load_img(img_path, target_size=(128, 128))  # Resize to 128x128
                img_array = tf.keras.utils.img_to_array(img_array)
                data.append(img_array)
                labels.append(CLASSES.index(label))
            except Exception as e:
                print(f"Error loading image {img_path}: {e}")

    return np.array(data), np.array(labels)

# Load data
data, labels = load_data(DATASET_PATH)

# Normalize pixel values
data = data / 255.0

# Convert labels to categorical format
labels = tf.keras.utils.to_categorical(labels, num_classes=len(CLASSES))

# Check data shape
print(f"Data shape: {data.shape}, Labels shape: {labels.shape}")

#  Split Data into Training and Testing Sets
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)

# Confirm splits
print(f"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}")
print(f"Testing data shape: {X_test.shape}, Testing labels shape: {y_test.shape}")

# Build the CNN Model
def create_model():
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(len(CLASSES), activation='softmax')
    ])
    return model

model = create_model()
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Display model summary
model.summary()

#  Train the Model
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
train_generator = train_datagen.flow(X_train, y_train, batch_size=32)

# Train the model
history = model.fit(train_generator, epochs=10, validation_data=(X_test, y_test))

# Save the model
model.save("lung_cancer_detection_model.h5")
print("Model saved as lung_cancer_detection_model.h5")

# Evaluate the Model
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)
print(f"Test accuracy: {test_acc}")

# Plot training performance
plt.figure(figsize=(12, 4))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.legend()
plt.title('Accuracy over epochs')

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend()
plt.title('Loss over epochs')
plt.show()

import os
from tensorflow.keras.models import load_model
from tensorflow.keras.utils import load_img, img_to_array

# Specify dataset path to dynamically detect class labels
DATASET_PATH = r"C:\Users\hariharan\Documents\lung_colon_image_set\lung_image_sets"
CLASSES = os.listdir(DATASET_PATH)  # Dynamically list subdirectories as class labels
print(f"Detected classes: {CLASSES}")

# Load the trained model
MODEL_PATH = "lung_cancer_detection_model.h5"
model = load_model(MODEL_PATH)
print("Model loaded successfully.")
